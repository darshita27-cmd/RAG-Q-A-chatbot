{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darshita27-cmd/RAG-Q-A-chatbot/blob/main/mymodel_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # for data manipulation, data cleaning\n",
        "from langchain.document_loaders import DataFrameLoader # this loads the dataset in the format for processing in NLP\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter # this splits the text into smaller chunks based on criteria( such as word cound, paragraph boundaries ) for further NLP tasks\n",
        "from langchain.vectorstores import Chroma # for vector embedding. chroma is to implement the vector embedding\n",
        "from langchain.embeddings import HuggingFaceEmbeddings # for numerical represention in vector in graphs\n",
        "from langchain.llms import HuggingFacePipeline # for text summerization,generation,translation\n",
        "from langchain.chains import RetrievalQA # for retival of answers and questions. generates answers based on data\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline # automodelforcasualllm is to generate text, autotokenizer coverts text to format models can understand\n",
        "import torch # provides tools for tensor computing\n",
        "def load_dataset(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.fillna('Unknown')  # Replace NaN with 'Unknown'\n",
        "    df['text'] = df.apply(lambda row: f\"Loan ID: {row['Loan_ID']}, Gender: {row['Gender']}, \"f\"Married: {row['Married']}, Dependents: {row['Dependents']}, \"f\"Education: {row['Education']}, Self_Employed: {row['Self_Employed']}, \"f\"Applicant Income: {row['ApplicantIncome']}, \"f\"Coapplicant Income: {row['CoapplicantIncome']}, \"f\"Loan Amount: {row['LoanAmount']}, \"f\"Loan Term: {row['Loan_Amount_Term']}, \"f\"Credit History: {row['Credit_History']}, \"\"Property Area: {row['Property_Area']}, \"f\"Loan Status: {row['Loan_Status']}\", axis=1)\n",
        "    return df\n",
        "def prepare_documents(df):\n",
        "    loader = DataFrameLoader(df, page_content_column=\"text\")\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50) # distributing the the dataset with 500 characters and chuck_oberlap is.. for ex if 0 to 500 are in first chunk that 450 to 950 will be in the next chunk. helps in sequence\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "    return docs\n",
        "def setup_retriever(docs):\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"distilbert-base-uncased\")\n",
        "    vectorstore = Chroma.from_documents(docs, embeddings)\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "    return retriever\n",
        "def setup_llm():\n",
        "    model_name = \"distilgpt2\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100)\n",
        "    llm = HuggingFacePipeline(pipeline=pipe)\n",
        "    return llm\n",
        "def create_rag_chain(retriever, llm):\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm=llm,chain_type=\"stuff\",retriever=retriever,return_source_documents=True)\n",
        "    return qa_chain\n",
        "def answer_query(query, qa_chain):\n",
        "    result = qa_chain({\"query\": query})\n",
        "    answer = result[\"result\"]\n",
        "    sources = [doc.page_content for doc in result[\"source_documents\"]]\n",
        "    return answer, sources\n",
        "def chatbot(file_path):\n",
        "    df = load_dataset(file_path)\n",
        "    docs = prepare_documents(df)\n",
        "    retriever = setup_retriever(docs)\n",
        "    llm = setup_llm()\n",
        "    qa_chain = create_rag_chain(retriever, llm)\n",
        "    print(\"\\nChatbot is ready! Type your question (or 'quit' to exit):\")\n",
        "    while True:\n",
        "        query = input(\"> \")\n",
        "        if query.lower() == 'quit':\n",
        "            print(\"Exiting chatbot...\")\n",
        "            break\n",
        "        print(\"Processing...\")\n",
        "        answer, sources = answer_query(query, qa_chain)\n",
        "        print(\"\\nAnswer:\", answer)\n",
        "        print(\"\\nSources:\")\n",
        "        for i, source in enumerate(sources, 1):\n",
        "            print(f\"{i}. {source}\")\n",
        "        print(\"\\nAsk another question (or type 'quit' to exit):\")\n",
        "if __name__ == \"__main__\":\n",
        "    # Update this path after uploading the CSV to Colab\n",
        "    file_path = \"/content/Training Dataset.csv\"\n",
        "    chatbot(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM1oya4FtBhk",
        "outputId": "a9eb1220-788b-43f4-fab9-25072c02dc25"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name distilbert-base-uncased. Creating a new one with mean pooling.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Chatbot is ready! Type your question (or 'quit' to exit):\n",
            "> How many loans were approved for self-employed applicants?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-19-3014368662.py:37: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain({\"query\": query})\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing...\n",
            "\n",
            "Answer: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "Loan ID: LP001245, Gender: Male, Married: Yes, Dependents: 2, Education: Not Graduate, Self_Employed: Yes, Applicant Income: 1875, Coapplicant Income: 1875.0, Loan Amount: 97.0, Loan Term: 360.0, Credit History: 1.0, Property Area: {row['Property_Area']}, Loan Status: Y\n",
            "\n",
            "Loan ID: LP001245, Gender: Male, Married: Yes, Dependents: 2, Education: Not Graduate, Self_Employed: Yes, Applicant Income: 1875, Coapplicant Income: 1875.0, Loan Amount: 97.0, Loan Term: 360.0, Credit History: 1.0, Property Area: {row['Property_Area']}, Loan Status: Y\n",
            "\n",
            "Loan ID: LP001245, Gender: Male, Married: Yes, Dependents: 2, Education: Not Graduate, Self_Employed: Yes, Applicant Income: 1875, Coapplicant Income: 1875.0, Loan Amount: 97.0, Loan Term: 360.0, Credit History: 1.0, Property Area: {row['Property_Area']}, Loan Status: Y\n",
            "\n",
            "Question: How many loans were approved for self-employed applicants?\n",
            "Helpful Answer: No, about 1,000 failed applications are rejected. Some applications do not have at least one form of application, and some are made for self-employed.\n",
            "Loan ID: LP001245, Gender: Male, Married: Yes, Dependents: 2, Education: Not Graduate, Self_Employed: Yes, Applicant Income: 1875, Coapplicant Income: 1875.0, Loan Amount: 97.0, Loan Term: 360.0, Credit History\n",
            "\n",
            "Sources:\n",
            "1. Loan ID: LP001245, Gender: Male, Married: Yes, Dependents: 2, Education: Not Graduate, Self_Employed: Yes, Applicant Income: 1875, Coapplicant Income: 1875.0, Loan Amount: 97.0, Loan Term: 360.0, Credit History: 1.0, Property Area: {row['Property_Area']}, Loan Status: Y\n",
            "2. Loan ID: LP001245, Gender: Male, Married: Yes, Dependents: 2, Education: Not Graduate, Self_Employed: Yes, Applicant Income: 1875, Coapplicant Income: 1875.0, Loan Amount: 97.0, Loan Term: 360.0, Credit History: 1.0, Property Area: {row['Property_Area']}, Loan Status: Y\n",
            "3. Loan ID: LP001245, Gender: Male, Married: Yes, Dependents: 2, Education: Not Graduate, Self_Employed: Yes, Applicant Income: 1875, Coapplicant Income: 1875.0, Loan Amount: 97.0, Loan Term: 360.0, Credit History: 1.0, Property Area: {row['Property_Area']}, Loan Status: Y\n",
            "\n",
            "Ask another question (or type 'quit' to exit):\n",
            "> quit\n",
            "Exiting chatbot...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}